{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('cs-training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                int64\n",
       "SeriousDlqin2yrs                          int64\n",
       "RevolvingUtilizationOfUnsecuredLines    float64\n",
       "age                                       int64\n",
       "NumberOfTime30-59DaysPastDueNotWorse      int64\n",
       "DebtRatio                               float64\n",
       "MonthlyIncome                           float64\n",
       "NumberOfOpenCreditLinesAndLoans           int64\n",
       "NumberOfTimes90DaysLate                   int64\n",
       "NumberRealEstateLoansOrLines              int64\n",
       "NumberOfTime60-89DaysPastDueNotWorse      int64\n",
       "NumberOfDependents                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dataset['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "def data_split_test_train (X,y, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = 0)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=data_split_test_train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visulaize(dataset, variable):\n",
    "    for i in variable:\n",
    "        if(dataset[i].dtypes == 'float64'):\n",
    "            A=dataset[i]\n",
    "            #plot.clear()\n",
    "            plt.figure(i)\n",
    "            sns.distplot(A[~np.isnan(A)])\n",
    "            #plot.show()\n",
    "            #\n",
    "        else:\n",
    "            #plot.clear()\n",
    "            A=dataset[i]\n",
    "            plt.figure(i)\n",
    "            sns.distplot(A[~np.isnan(A)])\n",
    "            #A.hist(bins=1000)\n",
    "            #plt.show()\n",
    "            #plot.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visulaizeWO(dataset, variable):\n",
    "    for i in variable:\n",
    "        if(dataset[i].dtypes == 'float64'):\n",
    "            A=dataset[i]\n",
    "            #plot.clear()\n",
    "            plt.figure(i)\n",
    "            plt.boxplot(A[~np.isnan(A)], sym='')\n",
    "        else:\n",
    "            #plot.clear()\n",
    "            print (\"later\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "later\n",
      "later\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x165b0128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bac6550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12ba7198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visulaizeWO(dataset,['NumberOfDependents', 'MonthlyIncome', 'DebtRatio', 'age', 'SeriousDlqin2yrs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_by_IQR(df,column, percentile=0.99):\n",
    "    for i in column:\n",
    "        q3 = df[i].quantile(0.99)\n",
    "        iqr = (df[i] < q3)\n",
    "        return df.loc[iqr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_subset_by_IQR(dataset,['MonthlyIncome', 'age'], 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect observations with more than one outlier\n",
    "\n",
    "def outlier_hunt(df):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than 2 outliers. \n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in df.columns.tolist():\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        \n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        \n",
    "        # Interquartile rrange (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > 2 )\n",
    "    print('The dataset contains %d observations with more than 2 outliers' %(len(outlier_hunt(df[features]))))\n",
    "    return multiple_outliers   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value_imputation(df, variables):\n",
    "        x = {}\n",
    "        for i in variables:\n",
    "            if(dataset[i].dtypes == 'float64'):\n",
    "                x[i]=df[i].fillna(df[i].median())\n",
    "    \n",
    "                #dataset.fillna(dataset.mean(), inplace=True)\n",
    "            else:\n",
    "                pass\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=missing_value_imputation(dataset, ['MonthlyIncome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new columns indicating what will be imputed\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "cols_with_missing = (col for col in new_data.columns \n",
    "                                 if new_data[col].isnull().any())\n",
    "for col in cols_with_missing:\n",
    "    new_data[col + '_was_missing'] = new_data[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "my_imputer = Imputer()\n",
    "new_data = my_imputer.fit_transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "def preprocessing(X_train, X_test):\n",
    "    X_train_scale=scale(X_train)\n",
    "    X_test_scale=scale(X_test)\n",
    "    return (X_train_scale, X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lable Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def LabelEncoding():\n",
    "    le=LabelEncoder()\n",
    "    for col in X_test.columns.values:\n",
    "        if X_test[col].dtypes=='object':\n",
    "            data=X_train[col].append(X_test[col])\n",
    "            le.fit(data.values)\n",
    "            X_train[col]=le.transform(X_train[col])\n",
    "            X_test[col]=le.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "def One_hot_encoding(X_train, X_test, columns):\n",
    "    for col in columns:\n",
    "        # creating an exhaustive list of all possible categorical values\n",
    "        data=X_train[[col]].append(X_test[[col]])\n",
    "        enc.fit(data)\n",
    "        # Fitting One Hot Encoding on train data\n",
    "        temp = enc.transform(X_train[[col]])\n",
    "        # Changing the encoded features into a data frame with new column names\n",
    "        temp=pd.DataFrame(temp,columns=[(col+\"_\"+str(i)) for i in data[col].value_counts().index])\n",
    "        # In side by side concatenation index values should be same\n",
    "        # Setting the index values similar to the X_train data frame\n",
    "        temp=temp.set_index(X_train.index.values)\n",
    "        # adding the new One Hot Encoded varibales to the train data frame\n",
    "        X_train_1=pd.concat([X_train_1,temp],axis=1)\n",
    "        # fitting One Hot Encoding on test data\n",
    "        temp = enc.transform(X_test[[col]])\n",
    "        # changing it into data frame and adding column names\n",
    "        temp=pd.DataFrame(temp,columns=[(col+\"_\"+str(i)) for i in data[col].value_counts().index])\n",
    "        # Setting the index for proper concatenation\n",
    "        temp=temp.set_index(X_test.index.values)\n",
    "        # adding the new One Hot Encoded varibales to test data frame\n",
    "        X_test_1=pd.concat([X_test_1,temp],axis=1)\n",
    "    return (X_train_1, X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "def Linear_Regression_basic(X_train, X_test, y_train, y_test):\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train,y_train)\n",
    "    print(lm.intercept_)\n",
    "    coef=pd.DataFrame(lm.coef_,X.columns,columns=['Coefficient'])\n",
    "    print (coef)\n",
    "    predictions = lm.predict(X_test)\n",
    "    print(predictions)\n",
    "    print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "    print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kypred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-266-2720585f7b87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkypred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'kypred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "def Logistic_Regression_basic():\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    print(y_pred)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "    print(mt.accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_and_recall(precision, recall, threshold):\n",
    "    plt.plot(threshold, precision[:-1], \"r-\", label=\"precision\", linewidth=5)\n",
    "    plt.plot(threshold, recall[:-1], \"b\", label=\"recall\", linewidth=5)\n",
    "    plt.xlabel(\"threshold\", fontsize=19)\n",
    "    plt.legend(loc=\"upper right\", fontsize=19)\n",
    "    plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_vs_recall(precision, recall):\n",
    "    plt.plot(recall, precision, \"g--\", linewidth=2.5)\n",
    "    plt.ylabel(\"recall\", fontsize=19)\n",
    "    plt.xlabel(\"precision\", fontsize=19)\n",
    "    plt.axis([0, 1.5, 0, 1.5])\n",
    "    \n",
    "def plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n",
    "    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate (TPR)', fontsize=16)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_boxcox = []\n",
    "\n",
    "for feature in features:\n",
    "    bc_transformed, _ = boxcox(df[feature]+1)  # shift by 1 to avoid computing log of negative values\n",
    "    features_boxcox.append(bc_transformed)\n",
    "\n",
    "features_boxcox = np.column_stack(features_boxcox)\n",
    "df_bc = pd.DataFrame(data=features_boxcox, columns=features)\n",
    "df_bc['Type'] = df['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "pipelines = []\n",
    "n_estimators = 200\n",
    "\n",
    "#print(df.shape)\n",
    "pipelines.append( ('SVC',\n",
    "                   Pipeline([\n",
    "                              ('sc', StandardScaler()),\n",
    "#                               ('pca', PCA(n_components = n_components, random_state=seed ) ),\n",
    "                             ('SVC', SVC(random_state=seed))]) ) )\n",
    "\n",
    "\n",
    "pipelines.append(('KNN',\n",
    "                  Pipeline([ \n",
    "                              ('sc', StandardScaler()),\n",
    "#                             ('pca', PCA(n_components = n_components, random_state=seed ) ),\n",
    "                            ('KNN', KNeighborsClassifier()) ])))\n",
    "pipelines.append( ('RF',\n",
    "                   Pipeline([\n",
    "                              ('sc', StandardScaler()),\n",
    "#                              ('pca', PCA(n_components = n_components, random_state=seed ) ), \n",
    "                             ('RF', RandomForestClassifier(random_state=seed, n_estimators=n_estimators)) ]) ))\n",
    "\n",
    "\n",
    "pipelines.append( ('Ada',\n",
    "                   Pipeline([ \n",
    "                              ('sc', StandardScaler()),\n",
    "#                              ('pca', PCA(n_components = n_components, random_state=seed ) ), \n",
    "                    ('Ada', AdaBoostClassifier(random_state=seed,  n_estimators=n_estimators)) ]) ))\n",
    "\n",
    "pipelines.append( ('ET',\n",
    "                   Pipeline([\n",
    "                              ('sc', StandardScaler()),\n",
    "#                              ('pca', PCA(n_components = n_components, random_state=seed ) ), \n",
    "                             ('ET', ExtraTreesClassifier(random_state=seed, n_estimators=n_estimators)) ]) ))\n",
    "pipelines.append( ('GB',\n",
    "                   Pipeline([ \n",
    "                             ('sc', StandardScaler()),\n",
    "#                             ('pca', PCA(n_components = n_components, random_state=seed ) ), \n",
    "                             ('GB', GradientBoostingClassifier(random_state=seed)) ]) ))\n",
    "\n",
    "pipelines.append( ('LR',\n",
    "                   Pipeline([\n",
    "                              ('sc', StandardScaler()),\n",
    "#                               ('pca', PCA(n_components = n_components, random_state=seed ) ), \n",
    "                             ('LR', LogisticRegression(random_state=seed)) ]) ))\n",
    "\n",
    "results, names, times  = [], [] , []\n",
    "num_folds = 10\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in pipelines:\n",
    "    start = time()\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring = scoring,\n",
    "                                n_jobs=-1) \n",
    "    t_elapsed = time() - start\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    times.append(t_elapsed)\n",
    "    msg = \"%s: %f (+/- %f) performed in %f seconds\" % (name, 100*cv_results.mean(), \n",
    "                                                       100*cv_results.std(), t_elapsed)\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))    \n",
    "fig.suptitle(\"Algorithms comparison\")\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with a Random forest classifier\n",
    "pipe_rfc = Pipeline([ \n",
    "                      ('scl', StandardScaler()), \n",
    "                    ('rfc', RandomForestClassifier(random_state=seed, n_jobs=-1) )])\n",
    "\n",
    "# Set the grid parameters\n",
    "param_grid_rfc =  [ {\n",
    "    'rfc__n_estimators': [100, 200,300,400], # number of estimators\n",
    "    #'rfc__criterion': ['gini', 'entropy'],   # Splitting criterion\n",
    "    'rfc__max_features':[0.05 , 0.1], # maximum features used at each split\n",
    "    'rfc__max_depth': [None, 5], # Max depth of the trees\n",
    "    'rfc__min_samples_split': [0.005, 0.01], # mininal samples in leafs\n",
    "    }]\n",
    "# Use 10 fold CV\n",
    "kfold = StratifiedKFold(n_splits=num_folds, random_state= seed)\n",
    "grid_rfc = GridSearchCV(pipe_rfc, param_grid= param_grid_rfc, cv=kfold, scoring=scoring, verbose= 1, n_jobs=-1)\n",
    "\n",
    "#Fit the pipeline\n",
    "start = time()\n",
    "grid_rfc = grid_rfc.fit(X_train, y_train)\n",
    "end = time()\n",
    "\n",
    "print(\"RFC grid search took %.3f seconds\" %(end-start))\n",
    "\n",
    "# Best score and best parameters\n",
    "print('-------Best score----------')\n",
    "print(grid_rfc.best_score_ * 100.0)\n",
    "print('-------Best params----------')\n",
    "print(grid_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(train_sizes, train_scores, test_scores, title, alpha=0.1):\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    plt.plot(train_sizes, train_mean, label='train score', color='blue', marker='o')\n",
    "    plt.fill_between(train_sizes,train_mean + train_std,\n",
    "                    train_mean - train_std, color='blue', alpha=alpha)\n",
    "    plt.plot(train_sizes, test_mean, label='test score', color='red',marker='o')\n",
    "    plt.fill_between(train_sizes,test_mean + test_std, test_mean - test_std , color='red', alpha=alpha)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Number of training points')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(ls='--')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()    \n",
    "    \n",
    "def plot_validation_curve(param_range, train_scores, test_scores, title, alpha=0.1):\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    plt.plot(param_range, train_mean, label='train score', color='blue', marker='o')\n",
    "    plt.fill_between(param_range,train_mean + train_std,\n",
    "                    train_mean - train_std, color='blue', alpha=alpha)\n",
    "    plt.plot(param_range, test_mean, label='test score', color='red', marker='o')\n",
    "    plt.fill_between(param_range,test_mean + test_std, test_mean - test_std , color='red', alpha=alpha)\n",
    "    plt.title(title)\n",
    "    plt.grid(ls='--')\n",
    "    plt.xlabel('Parameter value')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "              estimator= grid_rfc.best_estimator_ , X= X_train, y = y_train, \n",
    "                train_sizes=np.arange(0.1,1.1,0.1), cv= 10,  scoring='accuracy', n_jobs= - 1)\n",
    "\n",
    "plot_learning_curve(train_sizes, train_scores, test_scores, title='Learning curve for RFC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out-of-fold predictions\n",
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)\n",
    "\n",
    "\n",
    "\n",
    "et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\n",
    "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \n",
    "gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\n",
    "svc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier\n",
    "\n",
    "\n",
    "\n",
    "rf_feature = rf.feature_importances(x_train,y_train)\n",
    "et_feature = et.feature_importances(x_train, y_train)\n",
    "ada_feature = ada.feature_importances(x_train, y_train)\n",
    "gb_feature = gb.feature_importances(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state = seed)\n",
    "pca.fit(X_train)\n",
    "var_exp = pca.explained_variance_ratio_\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.bar(range(1,len(cum_var_exp)+1), var_exp, align= 'center', label= 'individual variance explained', \\\n",
    "       alpha = 0.7)\n",
    "plt.step(range(1,len(cum_var_exp)+1), cum_var_exp, where = 'mid' , label= 'cumulative variance explained', \\\n",
    "        color= 'red')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.xticks(np.arange(1,len(var_exp)+1,1))\n",
    "plt.legend(loc='center right')\n",
    "plt.show()\n",
    "\n",
    "# Cumulative variance explained\n",
    "for i, sum in enumerate(cum_var_exp):\n",
    "    print(\"PC\" + str(i+1), \"Cumulative variance: %.3f% %\" %(cum_var_exp[i]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "\n",
    "def replace_contractions(text):\n",
    "    \"\"\"Replace contractions in string of text\"\"\"\n",
    "    return contractions.fix(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "def stem_and_lemmatize(words):\n",
    "    stems = stem_words(words)\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return stems, lemmas\n",
    "\n",
    "stems, lemmas = stem_and_lemmatize(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
